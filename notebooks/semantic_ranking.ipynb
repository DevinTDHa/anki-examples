{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search\n",
    "Idea: Use text embeddings to find the example that is most similar to the translation.\n",
    "\n",
    "Model: https://huggingface.co/intfloat/multilingual-e5-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_translation(source, target):\n",
    "    # Format according to XLIFF\n",
    "    return f\"query: <source>{source}</source><target>{target}</target>\"\n",
    "\n",
    "\n",
    "def format_example(ex):\n",
    "    # Use \"query: \" prefix for symmetric tasks such as semantic similarity, bitext mining, paraphrase retrieval.\n",
    "    return f\"query: {ex}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing corpus from /media/ducha/SSDSHARED/VN/subs_dump/viet_subs_processed2\n",
      "Corpus prepared with 13646 files\n",
      "Total Examples 7736833\n"
     ]
    }
   ],
   "source": [
    "from find_examples import CorpusExamples\n",
    "\n",
    "corpus_folder = \"/media/ducha/SSDSHARED/VN/subs_dump/viet_subs_processed2\"\n",
    "corpus = CorpusExamples(corpus_folder)\n",
    "csv_path = \"/home/ducha/Dropbox/Tiếng Việt/Ngữ Vựng/1000.csv\"\n",
    "\n",
    "with open(csv_path, \"r\") as f:\n",
    "    csv_1k = [line.strip().split(\";\") for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi, en, _ = csv_1k[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: <source>cột</source><target>column</target>\n"
     ]
    }
   ],
   "source": [
    "query = format_translation(vi, en)\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_examples = corpus.find_examples(vi)\n",
    "len(found_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_formatted = [format_example(ex[\"text\"]) for ex in found_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"intfloat/multilingual-e5-small\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n"
     ]
    }
   ],
   "source": [
    "model_input = [query] + examples_formatted\n",
    "print(len(model_input))\n",
    "all_encoded = model.encode(\n",
    "    model_input,\n",
    "    normalize_embeddings=True,\n",
    "    device=\"cuda\",\n",
    "    convert_to_tensor=True,\n",
    "    convert_to_numpy=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_enc, examples_enc = all_encoded[0], all_encoded[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1099])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "similarities = torch.cosine_similarity(query_enc[None], examples_enc, dim=1)\n",
    "similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_sorted = (\n",
    "    torch.argsort(similarities, descending=True).cpu().detach().numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "found_ex_np = np.array([ex[\"text\"] for ex in found_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Đã cột và vào vị trí.', 'Cột ở phía này trước đi.',\n",
       "       'Cắt ở đây, cột ở chỗ kia.', ...,\n",
       "       'Ai không theo Kitô giáo được lọc ra, bị treo trên cột và bị thiêu chết?',\n",
       "       'Chúng ta sẽ cột tàu ở đó Jack có thể thấy chúng ta An toàn không?',\n",
       "       'Phelps được tìm thấy từ đỉnh cột cờ, có vẻ như cổ của anh ta Có nhân chứng không?'],\n",
       "      dtype='<U92')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_ex_np[similarities_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
